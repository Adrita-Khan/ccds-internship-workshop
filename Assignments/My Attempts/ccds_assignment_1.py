# -*- coding: utf-8 -*-
"""CCDS Assignment 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hgmdkbn7d3nAOVmjhzs0v2cTpFjOzBO6
"""

pip install torch torchvision matplotlib scikit-learn

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, f1_score, ConfusionMatrixDisplay
import seaborn as sns

# Define transformations: Convert images to tensors and normalize them
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  # Normalize to mean=0.5, std=0.5
])

# Download and load the training and test datasets
train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)

# Split the training dataset into training and validation sets
train_size = int(0.8 * len(train_dataset))  # 80% for training
val_size = len(train_dataset) - train_size  # 20% for validation
train_set, val_set = random_split(train_dataset, [train_size, val_size])

# Define DataLoaders with batch size 1024
batch_size = 1024

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# EDA: Inspect dataset structure
print(f"Training set size: {len(train_set)}")
print(f"Validation set size: {len(val_set)}")
print(f"Test set size: {len(test_dataset)}")

# Class labels in FashionMNIST
class_labels = [
    "T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
    "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"
]

# Function to visualize images
def visualize_samples(dataset, n_samples=10):
    fig, axes = plt.subplots(1, n_samples, figsize=(15, 2))
    for i in range(n_samples):
        idx = np.random.randint(0, len(dataset))
        image, label = dataset[idx]
        image = image.numpy().squeeze()  # Remove single channel
        axes[i].imshow(image, cmap='gray')
        axes[i].set_title(class_labels[label])
        axes[i].axis('off')
    plt.show()

print("Sample images from the training set:")
visualize_samples(train_set, n_samples=10)

# Class distribution in the training set
train_labels = [train_dataset.targets[idx] for idx in train_set.indices]
val_labels = [train_dataset.targets[idx] for idx in val_set.indices]

def plot_class_distribution(labels, title):
    plt.figure(figsize=(8, 5))
    plt.hist(labels, bins=np.arange(11) - 0.5, rwidth=0.8, align='mid')
    plt.xticks(range(10), class_labels, rotation=45)
    plt.xlabel("Class")
    plt.ylabel("Frequency")
    plt.title(title)
    plt.show()

print("Class distribution in the training set:")
plot_class_distribution(train_labels, "Training Set Class Distribution")

print("Class distribution in the validation set:")
plot_class_distribution(val_labels, "Validation Set Class Distribution")

# Check data ranges and shapes
batch = next(iter(train_loader))
images, labels = batch
print("Image tensor shape:", images.shape)
print("Label tensor shape:", labels.shape)
print("Image pixel range:", (images.min().item(), images.max().item()))

# Additional EDA: Image statistics
mean_pixel_value = images.mean().item()
std_pixel_value = images.std().item()
print(f"Mean pixel value (normalized): {mean_pixel_value:.4f}")
print(f"Std pixel value (normalized): {std_pixel_value:.4f}")

# Additional visualization: Grid of images
def visualize_grid(loader, n_images=25):
    images, labels = next(iter(loader))
    images = images[:n_images]
    labels = labels[:n_images]
    grid_size = int(np.ceil(np.sqrt(n_images)))
    fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))
    axes = axes.flatten()
    for i in range(n_images):
        image = images[i].numpy().squeeze()
        axes[i].imshow(image, cmap='gray')
        axes[i].set_title(class_labels[labels[i]])
        axes[i].axis('off')
    for i in range(n_images, len(axes)):
        axes[i].axis('off')
    plt.tight_layout()
    plt.show()

print("Grid of sample images from the training set:")
visualize_grid(train_loader, n_images=25)

# Additional Analysis: Validate normalization
unnormalized_images = images * 0.5 + 0.5  # Undo normalization
print("Unnormalized pixel range:", (unnormalized_images.min().item(), unnormalized_images.max().item()))

# Additional Analysis: Label counts in test set
test_labels = test_dataset.targets.numpy()
plot_class_distribution(test_labels, "Test Set Class Distribution")

# Additional EDA: Average image per class
def compute_average_images(dataset, num_classes=10):
    averages = torch.zeros((num_classes, 28, 28))
    counts = torch.zeros(num_classes)
    for image, label in dataset:
        averages[label] += image.squeeze()
        counts[label] += 1
    for i in range(num_classes):
        if counts[i] > 0:
            averages[i] /= counts[i]
    return averages

average_images = compute_average_images(train_set)

# Visualize average images per class
def visualize_average_images(averages, class_labels):
    fig, axes = plt.subplots(1, len(class_labels), figsize=(15, 5))
    for i, ax in enumerate(axes):
        ax.imshow(averages[i], cmap='gray')
        ax.set_title(class_labels[i])
        ax.axis('off')
    plt.show()

print("Average images per class in the training set:")
visualize_average_images(average_images, class_labels)

# Additional EDA: Variability per class
def compute_class_variability(dataset, num_classes=10):
    variances = torch.zeros((num_classes, 28, 28))
    counts = torch.zeros(num_classes)
    averages = compute_average_images(dataset, num_classes)
    for image, label in dataset:
        variances[label] += (image.squeeze() - averages[label]) ** 2
        counts[label] += 1
    for i in range(num_classes):
        if counts[i] > 0:
            variances[i] /= counts[i]
    return variances

class_variability = compute_class_variability(train_set)

# Visualize variability images per class
def visualize_variability_images(variances, class_labels):
    fig, axes = plt.subplots(1, len(class_labels), figsize=(15, 5))
    for i, ax in enumerate(axes):
        ax.imshow(variances[i], cmap='gray')
        ax.set_title(f"Var: {class_labels[i]}")
        ax.axis('off')
    plt.show()

print("Variability images per class in the training set:")
visualize_variability_images(class_variability, class_labels)

class FashionCNN(nn.Module):
    def __init__(self):
        super(FashionCNN, self).__init__()

        # Convolutional layers
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.relu1 = nn.ReLU()  # Using ReLU for convolutional layers

        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.relu2 = nn.ReLU()

        self.pool = nn.MaxPool2d(2, 2)  # Reduce spatial dimensions

        # Fully connected layers
        self.fc1 = nn.Linear(64 * 14 * 14, 128)  # Assuming input images are 28x28
        self.bn3 = nn.BatchNorm1d(128)
        self.sigmoid1 = nn.Sigmoid()

        self.fc2 = nn.Linear(128, 64)
        self.bn4 = nn.BatchNorm1d(64)
        self.sigmoid2 = nn.Sigmoid()

        self.fc3 = nn.Linear(64, 10)  # 10 classes for Fashion-MNIST

        # Initialize weights
        self._initialize_weights()

    def _initialize_weights(self):
        # Apply Xavier initialization to convolutional and linear layers
        for m in self.modules():
            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

    def forward(self, x):
        # Convolutional layers with ReLU and BatchNorm
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu1(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu2(x)

        x = self.pool(x)

        # Flatten the tensor for fully connected layers
        x = x.view(x.size(0), -1)

        # Fully connected layers with BatchNorm and Sigmoid
        x = self.fc1(x)
        x = self.bn3(x)
        x = self.sigmoid1(x)

        x = self.fc2(x)
        x = self.bn4(x)
        x = self.sigmoid2(x)

        x = self.fc3(x)  # Output layer (logits)

        return x

# Check for GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Instantiate the model and move it to the device
model = FashionCNN().to(device)

# Define loss function
criterion = nn.CrossEntropyLoss()

# Define optimizer with learning rate 0.001
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 20  # You can adjust the number of epochs

train_losses = []
val_losses = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass and optimize
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

    epoch_train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_train_loss)

    # Validation phase
    model.eval()
    val_running_loss = 0.0
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_running_loss += loss.item() * images.size(0)

    epoch_val_loss = val_running_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)

    print(f"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}")

plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')
plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)
plt.show()